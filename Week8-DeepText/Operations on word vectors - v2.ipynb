{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This notebook reads the GloVe data and shows that King:man =  Queen : Woman\n",
    "#, but some analogies do not wark as also shown.\n",
    "# This reads from glove 50dimesnion file, and finds nearest word to a analogy\n",
    "#Though it finds the missing word correctly for most words, for some it does not\n",
    "#R Chandrashekar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_data(glove_file):\n",
    "    with open(glove_file, 'r', encoding=\"utf-8\") as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        curr_word=None\n",
    "        i = 0\n",
    "        try:\n",
    "            for line in f:\n",
    "                i+=1\n",
    "                try:\n",
    "                    line = line.strip().split()\n",
    "                    curr_word = line[0]\n",
    "                    word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "                except Exception as E:\n",
    "                    print (\"got An exception, word=\", curr_word, i)\n",
    "                    pass         \n",
    "        except Exception as E:\n",
    "            print (\"got An exception before for, word=\", curr_word, i)\n",
    "            pass         \n",
    "            \n",
    "    return word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_vec_map = read_glove_data('glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224761"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_to_vec_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(vec_u, vec_v):\n",
    "    distance = 0.0   \n",
    "    dot = np.inner(vec_u,vec_v)\n",
    "    norm_vec_u = np.linalg.norm(vec_u)\n",
    "    norm_vec_v = np.linalg.norm(vec_v)\n",
    "    cos_similarity = dot/(norm_vec_u*norm_vec_v)\n",
    "    \n",
    "    return cos_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_similarity(father, mother) =  0.8909038442893615\n",
      "cos_similarity(ball, crocodile) =  0.2743924626137942\n",
      "cos_similarity(france - paris, rome - italy) =  0.6751479308174202\n",
      "cos_similarity(france - paris, rome - italy) =  -0.6751479308174202\n"
     ]
    }
   ],
   "source": [
    "fatherVec = word_to_vec_map[\"father\"]\n",
    "motherVec = word_to_vec_map[\"mother\"]\n",
    "ballVec = word_to_vec_map[\"ball\"]\n",
    "crocodileVec = word_to_vec_map[\"crocodile\"]\n",
    "franceVec = word_to_vec_map[\"france\"]\n",
    "italyVec = word_to_vec_map[\"italy\"]\n",
    "parisVec = word_to_vec_map[\"paris\"]\n",
    "romeVec = word_to_vec_map[\"rome\"]\n",
    "\n",
    "print(\"cos_similarity(father, mother) = \", cos_similarity(fatherVec, motherVec))\n",
    "print(\"cos_similarity(ball, crocodile) = \",cos_similarity(ballVec, crocodileVec))\n",
    "print(\"cos_similarity(france - paris, rome - italy) = \",cos_similarity(franceVec - parisVec, \n",
    "                                                                          italyVec - romeVec))\n",
    "print(\"cos_similarity(france - paris, rome - italy) = \",cos_similarity(franceVec - parisVec, \n",
    "                                                                          romeVec - italyVec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMissing(word_a, word_b, word_c, word_to_vec_map):\n",
    "    word_a, word_b, word_c = word_a.lower(), word_b.lower(), word_c.lower()\n",
    "    \n",
    "    e_a, e_b, e_c = word_to_vec_map[word_a], word_to_vec_map[word_b], word_to_vec_map[word_c]#None\n",
    "    words = word_to_vec_map.keys()\n",
    "    max_cosine_sim = -1000              \n",
    "    best_word = None                   \n",
    "\n",
    "    for w in words:        \n",
    "        if w in [word_a, word_b, word_c] :\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            cosine_sim = cos_similarity(e_b-e_a, word_to_vec_map[w]-e_c)\n",
    "        \n",
    "            if (cosine_sim > max_cosine_sim):\n",
    "                max_cosine_sim = cosine_sim\n",
    "                best_word = w\n",
    "        except ValueError as ve:\n",
    "            print (\"Got an exception\", ve, w)\n",
    "            pass\n",
    "        except KeyError as ke:\n",
    "            print (\"this key\", w, \"not found\")\n",
    "            \n",
    "    print (\"Done\")    \n",
    "    return best_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word_to_vec_map[\"usa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6958505344885514  for paris\n",
      "0.7249669057754777  for nanterre <class 'numpy.ndarray'> (50,)\n"
     ]
    }
   ],
   "source": [
    "word_a, word_b, word_c= 'india', 'delhi', 'france'\n",
    "w = \"paris\"\n",
    "e_a, e_b, e_c = word_to_vec_map[word_a], word_to_vec_map[word_b], word_to_vec_map[word_c]\n",
    "cosine_sim = cos_similarity(e_b-e_a, word_to_vec_map[w]-e_c)\n",
    "print (cosine_sim ,\" for paris\")\n",
    "w = \"nanterre\"\n",
    "cosine_sim = cos_similarity(e_b-e_a, word_to_vec_map[w]-e_c)\n",
    "print (cosine_sim ,\" for nanterre\", type(e_a), e_a.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "('italy', 'italian', 'spain') spanish\n",
      "Done\n",
      "('father', 'mother', 'son') daughter\n",
      "Done\n",
      "('brother', 'sister', 'nephew') niece\n",
      "Done\n",
      "('india', 'delhi', 'japan') tokyo\n",
      "Done\n",
      "('man', 'woman', 'boy') girl\n",
      "Done\n",
      "('small', 'smaller', 'large') larger\n",
      "Done\n",
      "('king', 'man', 'queen') woman\n",
      "Done\n",
      "('king', 'woman', 'queen') girl\n"
     ]
    }
   ],
   "source": [
    "puzzle_triads= [('italy', 'italian', 'spain'), \n",
    "                 ('father', 'mother', 'son'),\n",
    "                 ('brother', 'sister', 'nephew'),\n",
    "                 ('india', 'delhi', 'japan'), \n",
    "                 ('man', 'woman', 'boy'), \n",
    "                 ('small', 'smaller', 'large'),\n",
    "                ('king', 'man', 'queen'),\n",
    "                 ('king', 'woman', 'queen')\n",
    "                ]\n",
    "for t in puzzle_triads:\n",
    "    print (t, findMissing(t[0], t[1], t[2], word_to_vec_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "8hb5s",
   "launcher_item_id": "5NrJ6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
